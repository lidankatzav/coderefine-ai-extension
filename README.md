# ğŸš€ Auto Code Improve â€” VS Code Extension

A lightweight VS Code extension that analyzes your code and suggests improvements using a **local LLM**.  
ğŸ”’ **100% Private** â€” No data is sent to the cloud. All processing happens locally on your machine.

---

## âœ¨ Features

- ğŸ” **Smart Code Analysis** â€” Analyzes your code and provides improvement suggestions
- ğŸ  **Fully Local** â€” Works with local LLM servers (LM Studio, Ollama, etc.)
- ğŸ¯ **Multi-Language Support** â€” Works with Python, TypeScript, and JavaScript
- âš¡ **Quick Access** â€” Available via toolbar button or command palette
- ğŸ“ **Markdown Output** â€” Suggestions displayed in a formatted markdown document

---

## ğŸ“‹ Requirements

- **VS Code** (version 1.105.0 or higher)
- **Local LLM Server** running at `http://127.0.0.1:1234`
  - Compatible with LM Studio, Ollama, or any OpenAI-compatible API server

---

## ğŸ› ï¸ Installation

### Option 1: Install from VSIX (if available)
1. Open VS Code
2. Go to Extensions view (`Ctrl+Shift+X` / `Cmd+Shift+X`)
3. Click the `...` menu â†’ "Install from VSIX..."
4. Select the `.vsix` file

### Option 2: Development Installation
1. Clone this repository
2. Open the `auto-code-improve` folder in VS Code
3. Run `npm install` to install dependencies
4. Press `F5` to open a new Extension Development Host window
5. The extension will be active in the new window

---

## ğŸ® How to Use

### Step 1: Start Your Local LLM Server

**Using LM Studio:**
1. Open LM Studio
2. Load a model
3. Click "Start Server" 
4. Make sure the OpenAI-compatible endpoint is enabled (default port: 1234)

**Using Ollama:**
```bash
ollama serve
# Then run: ollama run <model-name>
```

### Step 2: Use the Extension

**Method 1: Toolbar Button** ğŸ¯
1. Open any code file (Python, TypeScript, or JavaScript)
2. Click the **"âœ¨ Suggest Improvements"** button in the editor toolbar

**Method 2: Command Palette** âŒ¨ï¸
1. Open any code file
2. Press `Ctrl+Shift+P` (Windows/Linux) or `Cmd+Shift+P` (Mac)
3. Type "Auto Code Improve: Suggest Improvements"
4. Press Enter

**Method 3: Right-Click Context Menu** ğŸ–±ï¸
1. Right-click in your code editor
2. Select "Auto Code Improve: Suggest Improvements"

### Step 3: View Suggestions

- Suggestions will appear in a new markdown document opened beside your code
- Review the improvements and apply them manually to your code

---

## âš™ï¸ Configuration

The extension connects to your local LLM at:
- **Default URL**: `http://127.0.0.1:1234/v1/chat/completions`
- **Model**: `lmstudio-local`

To change the endpoint, modify the URL in `src/extension.ts` (line 39).

---

## ğŸ§ª Supported Languages

- ğŸ **Python** (`.py`)
- ğŸ“˜ **TypeScript** (`.ts`, `.tsx`)
- ğŸ“— **JavaScript** (`.js`, `.jsx`)

---

## ğŸ—ï¸ Development

### Building the Extension

```bash
cd auto-code-improve
npm install
npm run compile
```

### Running in Development Mode

1. Open the project in VS Code
2. Press `F5` to launch the Extension Development Host
3. Test the extension in the new window

### Project Structure

```
auto-code-improve/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ extension.ts      # Main extension code
â”œâ”€â”€ package.json          # Extension manifest
â”œâ”€â”€ tsconfig.json         # TypeScript configuration
â””â”€â”€ README.md             # This file
```

---

## ğŸ› Troubleshooting

### "Failed to call local LLM"
- âœ… Make sure your LLM server is running
- âœ… Check that the server is accessible at `http://127.0.0.1:1234`
- âœ… Verify the OpenAI-compatible API endpoint is enabled

### Extension not appearing
- âœ… Reload VS Code window (`Ctrl+R` / `Cmd+R`)
- âœ… Check that the extension is activated (check Output â†’ "Auto Code Improve")
- âœ… Ensure you're using a supported file type

### No suggestions received
- âœ… Check your LLM server logs for errors
- âœ… Verify the model is loaded and responding
- âœ… Try a different model if available

---

## ğŸ“ License

This project is open source and available for personal and educational use.

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

---

## ğŸ“§ Contact

For questions or support, please open an issue on the repository.

---

**Made with â¤ï¸ for developers who value privacy and local-first tools**
